```{r}
library(dplyr)
library(readr)
library(randomForest)
library(rpart)
```

```{r}
# Funcion que genera la matriz de confusión

sensitivity <- function(TP,FN) round(TP/(TP+FN),2)
specificity <- function(TN,FP) round(TN/(TN+FP),2)
precision <- function(TP,FP) round(TP/(TP+FP),2)
negative_predictive_value <- function(TN,FN) round(TN/(TN+FN),2)
accuracy <- function(TP,TN,FP,FN) round((TP+TN)/(TP+TN+FP+FN),2)

metrics_confusion_Matrix<-function(actual_class,predicted_class){
  n <- length(actual_class)
  predicted <- predicted_class[actual_class == predicted_class]
  notpredicted <- predicted_class[!(actual_class == predicted_class)]
  TP <- length(predicted[predicted == 1])
  TN <- length(predicted[predicted == 0])
  FP <- length(notpredicted[notpredicted == 1])
  FN <- length(notpredicted[notpredicted == 0])
  row1 <- c(n,"Predicted Positive","Predicted Negative"," ")
  row2 <- c("Actual Positive",TP,FN,sensitivity(TP,FN))
  row3 <- c("Actual Negative",FP,TN,specificity(TN,FP))
  row4 <- c(" ",precision(TP,FP),negative_predictive_value(TN,FN),accuracy(TP,TN,FP,FN))
  confusionMatrix <- rbind(row1,row2,row3,row4)
  return(confusionMatrix)
}

create_folds <- function(dataframe,folds_num){
  
  folds <- list()
  rows <- nrow(dataframe)
  fold_len <- as.integer(rows / folds_num)
  remaining_indexes = seq(1:rows)
  
  for (i in 1:folds_num){
    fold_indexes <- sample(remaining_indexes,fold_len,replace=FALSE)
    folds[[i]] <- dataframe[fold_indexes,]
    remaining_indexes <- setdiff(remaining_indexes, fold_indexes)
  }
  
  return(folds)
}

mean_std_confusion_matrix <- function (results,folds_num){
  TPV<-c()
  TNV<-c()
  FPV<-c()
  FNV<-c()
  n<-0
  for(i in seq(1,folds_num)){
    n <- as.numeric(results[[i]][1,1]) + n
    TPV <- c(TPV,as.numeric(results[[i]][2,2]))
    TNV <- c(TNV,as.numeric(results[[i]][3,3]))
    FPV <- c(FPV,as.numeric(results[[i]][3,2]))
    FNV <- c(FNV,as.numeric(results[[i]][2,3]))
  }
  TP<-round(sum(TPV)/folds_num,2)
  TN<-round(sum(TNV)/folds_num,2)
  FP<-round(sum(FPV)/folds_num,2)
  FN<-round(sum(FNV)/folds_num,2)
  f1 <-c(n,"Predicted Positive","Predicted Negative"," ",paste("TP std:",as.character(round(sd(TPV),2))))
  f2 <-c("Actual Positive",TP,FN,sensitivity(TP,FN),paste("FP std:",as.character(round(sd(FPV),2))))
  f3 <-c("Actual Negative",FP,TN,specificity(FP,TN),paste("TN std:",as.character(round(sd(TNV),2))))
  f4 <-c(" ",precision(TP,FP),negative_predictive_value(FN,TN),accuracy(TP,TN,FP,FN),paste("FN std:",as.character(round(sd(FNV),2))))
  matrix<-rbind(f1,f2,f3,f4)
  return(matrix)
}


cross_validation <- function(dataframe,folds_num){
  
  train_formula<-formula(inclinacion_peligrosa ~ especie+altura+diametro_tronco+seccion+long+lat)
  folds <- create_folds(dataframe,folds_num)
  
  results <- list()
  
  for(i in 1:folds_num){
    
    test_data <- folds[[i]]
    if(i<folds_num){
      train_data = folds[[i+1]]
    }else{
      train_data = folds[[1]]
    }
    
    for(j in 1:folds_num){
      if(i == j | (i==folds_num & j==1)){
        next
      }
      
      train_data <- merge(train_data,folds[[j]],all=TRUE)
    }

    
  test_data$especie[which(!(test_data$especie %in% unique(train_data$especie)))] <- NA
    
    
  tree_model<-rpart(formula=train_formula, data=train_data)
  
  p <- predict(tree_model,test_data,type="class")
  
  results[[i]] <- metrics_confusion_Matrix(test_data[[length(test_data)-2]],p)
  
  
  }
  result_matrix <- mean_std_confusion_matrix(results,folds_num)
  
  return(result_matrix)
  
  
}

```



```{r}
# Carga de los datasets de entrenamiento y validacion

#train_data <- read.csv("/home/pablo/Repositorios/ia-uncuyo-2022/tp7-ml/data/arbolado-publico-mendoza-2021-train.csv")

#test_data <- read.csv("/home/pablo/Repositorios/ia-uncuyo-2022/tp7-ml/data/arbolado-publico-mendoza-2021-validation.csv")

# Los datasets utilizados para la parte A están desbalanceados, por lo que se va a generar un dataset más balanceado para realizar las pruebas

dataset <- read.csv("/home/pablo/Repositorios/ia-uncuyo-2022/tp7-ml/data/arbolado-mza-dataset.csv")


# Preprocesamiento

dataset$inclinacion_peligrosa <- factor(dataset$inclinacion_peligrosa)

# Se agrega nuevo feature : porcentaje de arboles peligrosos por especie en la población balanceada
peligrosos_total_especie <- dataset %>% group_by(especie) %>% summarise(total = n(), peligrosos_total = sum(inclinacion_peligrosa == 1))
rates <- data.frame(especie = peligrosos_total_especie$especie,
                     rate = peligrosos_total_especie$peligrosos_total/peligrosos_total_especie$total)

dataset <- merge(dataset, rates, by = "especie")

# Se cambia circunferencia del tronco, por la circunferencia de manera categorica categórica

dataset$circ_tronco_cm_cat <- cut(dataset$circ_tronco_cm, breaks = c(0, 40, 80, 120, Inf), labels = c("bajo", "medio", "alto","muy alto"))

# Formula para el entrenamiento

train_formula <- formula(inclinacion_peligrosa~altura+
                                              diametro_tronco+
                                              circ_tronco_cm+
                                              lat+
                                              long+
                                              seccion+
                                              especie+
                                              circ_tronco_cm_cat+
                                              rate)


# Balanceo de dataset

arboles_peligrosos <- dataset %>% filter(inclinacion_peligrosa == 1)

arboles_no_peligrosos <- dataset %>% filter(inclinacion_peligrosa == 0)

arboles_no_peligrosos_sample <- arboles_no_peligrosos[sample(1:(nrow(arboles_peligrosos)*1.5)),]

arboles <- merge(arboles_peligrosos,arboles_no_peligrosos_sample,all=TRUE)

random_indexes = sample(seq(arboles$id),size=nrow(arboles)*0.8,replace=FALSE)
train_data <- arboles[random_indexes,]
test_data <- arboles[-random_indexes,]

# Se quitan las especies que tienen menos de 3 ejemplares

low_examples_species <- train_data %>% group_by(especie) %>% summarise(n=n()) %>%
  filter(n<3) %>% select(especie)

train_data <- train_data %>% filter(!(especie %in% low_examples_species[[1]]))

train_data$inclinacion_peligrosa <- as.factor(train_data$inclinacion_peligrosa)

```

```{r}
# Generacion del árbol con random forest y la matriz de confusion para la predicción

tree_model <- randomForest(train_formula, data=train_data, ntree = 600)

submission_test <- read_csv("/home/pablo/Repositorios/ia-uncuyo-2022/tp7-ml/data/arbolado-mza-dataset-test.csv")


# Predicción para el archivo de validación con cross_validation
#print(cross_validation(train_data,3))

# Predicción para el archivo de validación con random forest
pred <- as.factor(predict(tree_model, test_data, type='class'))
matrix <- metrics_confusion_Matrix(pred,test_data$inclinacion_peligrosa)
matrix


# Se agrega la circunferencia de manera categórica y porcentaje de arboles con inclinación peligrosa por especie

#submission_test$circ_tronco_cm_cat <- cut(submission_test$circ_tronco_cm, breaks = c(0, 80, 160, 240, Inf), labels = c("bajo", "medio", "alto","muy alto"))

#submission_test <- merge(submission_test, rates, by = "especie")



# Predicción para el archivo de prueba de submisión

#pred <- as.factor(predict(tree_model, submission_test, type='class'))

```

```{r}
# Formateo del archivo para envío

result <- data.frame(id=submission_test$id,inclinacion_peligrosa=pred)
result$inclinacion_peligrosa <- as.numeric(result$inclinacion_peligrosa) 


write.csv(result,"/home/pablo/Repositorios/ia-uncuyo-2022/tp7-ml/data/submissions/report_14.csv", row.names = FALSE)

```


