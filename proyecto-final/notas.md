# Notas
El objetivo de estas notas es apuntar toda la informaci贸n que pueda ser 煤til tanto para el desarrollo del proyecto como para la elaboraci贸n del informe.

## Conceptos claves de cada libro y articulo seleccionados

### [1] Russell, S., & Norvig, P. (2010). Artificial Intelligence: A Modern Approach

#### Conceptos clave:
* Introducci贸n al Reinforcement Learning como un enfoque central para sistemas inteligentes aut贸nomos.
* Explicaci贸n de c贸mo los estados, acciones, y recompensas definen el marco del aprendizaje por refuerzo.
* Revisi贸n de modelos de decisi贸n y c贸mo estos influyen en el dise帽o de pol铆ticas.

#### Relevancia para el proyecto:
* Sirve como base conceptual para entender el marco general de los agentes inteligentes que pueden aplicarse en el dise帽o del agente de Quoridor.
* Proporciona herramientas te贸ricas para analizar decisiones y estrategias 贸ptimas en un entorno competitivo como Quoridor.

### [2] Sutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: An Introduction

#### Conceptos clave:
* Profundizaci贸n en el aprendizaje basado en pruebas y errores, con 茅nfasis en el equilibrio entre exploraci贸n y explotaci贸n.
* Desglose del Q-learning como un algoritmo clave de aprendizaje por refuerzo.
* Discusi贸n sobre el dise帽o de la funci贸n de recompensa y su impacto en el aprendizaje del agente.
* Explicaci贸n de c贸mo se modelan las pol铆ticas y su relaci贸n con los valores de estado y acci贸n.

#### Relevancia para el proyecto:
* Sirve como una gu铆a detallada para implementar Q-learning en el agente para Quoridor.
* Ayuda a estructurar las recompensas y pol铆ticas necesarias para entrenar un agente capaz de tomar decisiones estrat茅gicas en el juego.
* Permite entender c贸mo manejar las transiciones entre estados de un tablero din谩mico como el de Quoridor.

### [3] Lapan, M. (2018). Deep Reinforcement Learning Hands-On

#### Conceptos clave:

* Integraci贸n de Deep Learning con algoritmos de aprendizaje por refuerzo, como Q-learning y variantes como DQN.
* Aplicaciones pr谩cticas del aprendizaje por refuerzo en entornos complejos.


#### Relevancia para el proyecto:
* Ofrece ejemplos aplicados que pueden inspirar estrategias avanzadas para el agente de Quoridor, como combinar redes neuronales con Q-learning para explorar estados complejos.
* Es 煤til si es necesario ampliar el enfoque m谩s all谩 del cl谩sico Q-learning hacia m茅todos m谩s robustos para manejar m煤ltiples reglas o modificaciones.

### [4] Massagu茅 Respall, V., Brown, J., & Aslam, H. (2018). Monte Carlo Tree Search for Quoridor

#### Conceptos clave:
* Estudio detallado de la representaci贸n de estados y acciones en Quoridor.
* An谩lisis de c贸mo los m茅todos basados en Monte Carlo Tree Search (MCTS) pueden usarse para optimizar decisiones en este juego.

#### Relevancia para el proyecto:
* Proporciona una base para representar el tablero de Quoridor, las posiciones de los jugadores y las barreras como estados para el agente.
* Aunque se centra en MCTS, los conceptos de representaci贸n de estados y acciones son directamente aplicables para Q-learning.
* Permite comparar Q-learning con enfoques determin铆sticos como MCTS en t茅rminos de efectividad y complejidad computacional.

### [5] Wang, H., Emmerich, M., & Plaat, A. (2019). Assessing the Potential of Classical Q-learning in General Game Playing

#### Conceptos clave:
* Evaluaci贸n del desempe帽o de Q-learning en juegos generales, con 茅nfasis en c贸mo adaptar el algoritmo a diferentes escenarios.
* Discusi贸n sobre el impacto del dise帽o de la funci贸n de recompensa y la representaci贸n de las pol铆ticas en el 茅xito del agente.

#### Relevancia para el proyecto:
* Brinda ejemplos concretos de implementaci贸n de Q-learning en juegos, que pueden adaptarse a Quoridor.
* Discute las limitaciones del algoritmo en t茅rminos de tiempo de convergencia y la necesidad de dise帽ar recompensas efectivas, aspectos clave para el proyecto.
* Ayuda a entender c贸mo modelar estrategias para entornos como Quoridor, donde las reglas y los objetivos son espec铆ficos.

## Glosario de conceptos

### Aprendizaje por Refuerzo (Reinforcement Learning, RL)
El aprendizaje por refuerzo es un paradigma del aprendizaje autom谩tico donde un agente aprende a interactuar con un entorno tomando decisiones secuenciales para maximizar una recompensa acumulada a lo largo del tiempo. Basado en prueba y error, el agente debe equilibrar la exploraci贸n de nuevas acciones con la explotaci贸n de estrategias ya conocidas. En el contexto de Quoridor, este enfoque permite desarrollar un agente que aprenda a moverse estrat茅gicamente en el tablero, adapt谩ndose a la din谩mica del juego y a las decisiones del oponente.

### Estado (State)
Un estado representa una configuraci贸n del entorno en un momento dado, descrita por un conjunto de caracter铆sticas relevantes para el agente. En Quoridor, el estado se define por la posici贸n de los peones en el tablero, la distribuci贸n de las barreras y los movimientos disponibles. Capturar esta informaci贸n en un formato adecuado es esencial para que el agente pueda evaluar sus opciones y tomar decisiones informadas.

### Acci贸n (Action)
Una acci贸n es la decisi贸n que el agente toma en un estado particular para interactuar con el entorno, lo que genera una transici贸n hacia un nuevo estado. En Quoridor, las acciones incluyen mover el pe贸n a una casilla adyacente o colocar una barrera en una posici贸n v谩lida. Estas decisiones impactan directamente en el progreso hacia la meta del agente y en las posibilidades del oponente, lo que las convierte en un componente cr铆tico del aprendizaje.

### Pol铆tica (Policy)
La pol铆tica es la estrategia que gu铆a al agente en la selecci贸n de acciones seg煤n el estado en el que se encuentra. Puede ser determin铆stica, indicando una 煤nica acci贸n por estado, o estoc谩stica, asignando probabilidades a diferentes acciones. En Quoridor, dise帽ar una pol铆tica 贸ptima implica priorizar movimientos que acerquen al agente a su objetivo mientras se obstaculiza el progreso del adversario, maximizando las posibilidades de ganar.

### Funci贸n de Recompensa (Reward Function)
La funci贸n de recompensa asigna un valor num茅rico al agente como retroalimentaci贸n por realizar una acci贸n en un estado espec铆fico. En Quoridor, esta funci贸n puede dise帽arse para otorgar recompensas positivas por movimientos que acerquen al pe贸n del agente a la meta, o penalizaciones por acciones que no contribuyan al progreso, como colocar barreras que dificulten su propio camino. Este dise帽o es crucial para guiar el aprendizaje hacia estrategias efectivas.

### Q-learning
El Q-learning es un algoritmo de aprendizaje por refuerzo que actualiza valores de calidad (Q-values) para cada combinaci贸n de estado y acci贸n, aproximando una pol铆tica 贸ptima sin requerir un modelo expl铆cito del entorno. En Quoridor, el Q-learning permite al agente evaluar las posibles decisiones en cada turno, identificando movimientos que maximicen las recompensas acumuladas. Su capacidad para adaptarse a las transiciones din谩micas del tablero lo hace especialmente adecuado para este juego.

### Tabla Q (Q-table)
La Q-table es una estructura de datos utilizada en Q-learning para almacenar los valores Q asociados a cada par estado-acci贸n. En Quoridor, esta tabla es fundamental para evaluar qu茅 acciones son m谩s ventajosas en un estado dado. Sin embargo, dado el gran espacio de estados posibles en el tablero, podr铆a ser necesario utilizar t茅cnicas de aproximaci贸n para manejar la complejidad.

### Exploraci贸n vs Explotaci贸n
El dilema de exploraci贸n y explotaci贸n equilibra la necesidad de probar nuevas acciones para descubrir mejores recompensas y de aprovechar acciones previamente identificadas como beneficiosas. En Quoridor, un agente que explore demasiado podr铆a perder oportunidades claras de progreso, mientras que uno que solo explote estrategias conocidas podr铆a quedar atrapado en soluciones sub贸ptimas. Un buen balance entre ambos es clave para desarrollar estrategias adaptativas y efectivas.

### Factor de Descuento ()
El factor de descuento controla cu谩nto valora el agente las recompensas futuras en comparaci贸n con las inmediatas.

### Funci贸n de Valor (Value Function)
La funci贸n de valor estima la recompensa acumulada esperada para un estado o un par estado-acci贸n bajo una pol铆tica espec铆fica. En el contexto de Quoridor, esta funci贸n ayuda al agente a identificar estados ventajosos y a priorizar movimientos que maximicen su progreso hacia la meta.

### Entorno (Environment)
El entorno es el sistema con el que interact煤a el agente, respondiendo a sus acciones con nuevos estados y recompensas. En Quoridor, el entorno se define por el tablero, las posiciones de los jugadores, las barreras y las reglas del juego. Dise帽ar este entorno de manera precisa es esencial para que el agente comprenda y act煤e de manera efectiva en el juego.